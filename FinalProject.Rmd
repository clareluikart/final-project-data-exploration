---
title: "GEOG0114Final"
author: "Clare Rickard"
date: "2024-12-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Adding Libraries
```{r libraries}
#libraries used
library(here)
library(sf)
library(tmap)
library(sp)
library(janitor)
library(dplyr)
library(ggplot2)
library(terra)
library(tidycensus)
library(raster)
library(spdep)
library(e1071)
library(spatialreg)
library(spgwr)
library(car)
```
## Calculating NDVI
### Creating total NDVI area
```{r setup_NDVI_25, eval = FALSE}
# Step 1: Define input and output folders
input_folder <- "laip/" # Replace with your folder path
output_folder <- "laip/ndvi_output/" # Folder to save NDVI rasters

# Create output folder if it doesn't exist
if (!dir.exists(output_folder)) dir.create(output_folder)

# Step 2: Load all TIFs
tif_files <- list.files(input_folder, pattern = "\\.tif$", full.names = TRUE)

# Step 3: Process each TIF to calculate NDVI and save
for (tif_file in tif_files) {
  cat("Processing:", tif_file, "\n")
  
  # Load the TIF
  tif <- stack(tif_file)
  
  # Extract red and NIR bands (adjust band numbers if needed)
  red_band <- tif[[1]]
  nir_band <- tif[[4]]
  
  # Calculate NDVI
  ndvi <- (nir_band - red_band) / (nir_band + red_band)
  
  # Define output file name
  output_file <- gsub(".tif$", "_NDVI.tif", basename(tif_file))
  output_path <- file.path(output_folder, output_file)
  
  # Save the NDVI raster
  writeRaster(ndvi, output_path, format = "GTiff", overwrite = TRUE)
  
  cat("Saved NDVI raster to:", output_path, "\n")
}
```
### Classifying NDVI
``` {r NDVI_classify, eval=FALSE}
input_folder <- "laip/" # Replace with your folder path
output_folder <- "laip/ndvi_output/" # Folder to save NDVI rasters

# Step 4: List all NDVI rasters
ndvi_files <- list.files(output_folder, pattern = "_NDVI\\.tif$", full.names = TRUE)

# Step 7: Resample all NDVI rasters to the unified extent and resolution
cat("Resampling rasters...\n")
terra_rasters <- lapply(ndvi_files, function(ndvi_file) {
  r <- terra::rast(ndvi_file)
  return(r)
})

# Step 8: Mosaic resampled NDVI rasters together
cat("Mosaicking rasters...\n")
mosaicked_raster_NDVI <- do.call(merge, c(terra_rasters))
reclass_matrix <- matrix(c(
  -Inf, .2, 0,   # Less or equal to .2 -> class 0
  .2, Inf, 1   # More than .2 -> class 1
), ncol = 3, byrow = TRUE)
mosaicked_raster_NDVI <- classify(mosaicked_raster_NDVI, reclass_matrix, right=TRUE)

plot(mosaicked_raster_NDVI)

writeRaster(mosaicked_raster_NDVI, "mosaicked_raster_060_NDVI.tif", overwrite = TRUE)
cat("Mosaicked NDVI raster saved to:", mosaic_output_file_NDVI, "\n")
```
### Plotting NDVI at .6 meter resolution (NAD83 / UTM zone 10N (EPSG:26910))
```{r NDVI_25}
ndvi_25 <- rast("mosaicked_raster_060_NDVI.tif")
plot(ndvi_25)
```
## Calculating nDSM
### Setting up DEM
```{r setup25DEM, eval=FALSE}
# Define the folder containing the files
input_folder <- "nDSM_stuff/ca2023_sanfran_dem_Job1102345/"

# List all .tif files in the folder that end with "_XXX.tif"
dem_tifs <- list.files(path = input_folder, pattern = "_\\d{3}\\.tif$", full.names = TRUE)

# Check if the list is not empty
if (length(dem_tifs) == 0) {
  stop("No matching .tif files found in the directory.")
}

# Load and mosaic the rasters
rasters <- lapply(dem_tifs, terra::rast) # Ensure 'terra::rast' is used to load rasters
new_raster <- do.call(terra::mosaic, c(rasters, fun = "mean"))

# Save the result
output_file <- "mosaicked_dem_25.tif"
terra::writeRaster(new_raster, output_file, overwrite = TRUE)

cat("Mosaic saved to", output_file, "\n")
```
### Plotting DEM at .82-foot (.25 meter) resolution (NAD83(2011) / California zone 3 (ftUS) (EPSG:6420))
```{r import25DEM}
dem_raster <- rast("mosaicked_dem_25.tif")
plot(dem_raster, main = "Digital Elevation Model (.25m Resolution)")
```
### Setting up DSM
```{r setup_25DSM, eval = FALSE}
# List all chunk files
chunk_files <- list.files(path = "python_test/output_tifs/", pattern = "chunk_.*\\.tif$", full.names = TRUE)

# Load and mosaic the rasters
rasters <- lapply(chunk_files, rast)
new_raster <- do.call(terra::mosaic, c(rasters, fun = "mean"))

# Save the final mosaic
writeRaster(new_raster, "san_francisco_25_dsm.tif", overwrite = TRUE)
```
### Plotting DSM at (.25 meter) resolution (WGS 84 / Pseudo-Mercator (EPSG:3857) )
```{r import_25DSM}
dsm_raster <- rast("san_francisco_25_dsm.tif")
plot(dsm_raster, main = "Digital Surface Model (.25m Resolution)")
```
### Changing DEM vertical units from feet to metres
```{r metresDEM, eval=FALSE}
writeRaster((raster(here("mosaicked_dem_25.tif"))*0.3048), "dem_metres.tif", overwrite = TRUE)
```

### Subtracting DEM from DSM to get nDSM (WGS 84 / Pseudo-Mercator (EPSG:3857))
```{r setup25NDSM, eval=FALSE}
terra_dem <- terra::rast("dem_metres.tif")

terra_dsm <- terra::rast("san_francisco_25_dsm.tif")

terra_dem <- terra::project(terra_dem, terra_dsm, method="bilinear", res=.25)

terra_dsm <- terra::crop(terra_dsm, terra_dem, ext=TRUE)
terra_dem <- terra::crop(terra_dem, terra_dsm, ext=TRUE)

noaa_ndsm <- terra_dsm - terra_dem
writeRaster(noaa_ndsm, "san_francisco_ndsm_25.tif", overwrite = TRUE)
```
### Plotting nDSM at (.25 meter) resolution (WGS 84 / Pseudo-Mercator (EPSG:3857))
```{r import_NDSM_25}
noaa_ndsm <- rast("san_francisco_ndsm_25.tif")
plot(noaa_ndsm)
```
### Reclassifying nDSM to find areas above 8 feet
```{r classify_nDSM_25}
feet_to_meters <- function(feet) feet * 0.3048
threshold_1 <- feet_to_meters(1)   # 1 foot to meters
threshold_8 <- feet_to_meters(8)   # 8 feet to meters

# Reclassify raster
reclass_matrix <- matrix(c(
  -Inf, threshold_1, 1,   # Less than 1 foot -> class 1
  threshold_1, threshold_8, 2,   # 1-8 feet -> class 2
  threshold_8, Inf, 3     # Greater than 8 feet -> class 3
), ncol = 3, byrow = TRUE)

reclassified_raster_25 <- classify(noaa_ndsm, reclass_matrix)

# Define colors for the classes: yellow (class 1), blue (class 2), green (class 3)
colors <- c("yellow", "green", "blue")

writeRaster(reclassified_raster_25, "reclassified_25.tif", overwrite = TRUE)

# Plot the reclassified raster
plot(reclassified_raster_25, 
     col = colors, 
     legend = TRUE, 
     main = "Reclassified nDSM (Height Categories)",
     axes = FALSE, box = FALSE)
```

### Importing NDVI (NAD83 / UTM zone 10N (EPSG:26910)) and and Reclassified nDSM (WGS 84 / Pseudo-Mercator (EPSG:3857))
```{r import_NDVI_nDSM, eval=FALSE}
mosaicked_raster_NDVI <- rast("mosaicked_raster_060_NDVI.tif")
reclassified_raster_25 <- rast("reclassified_25.tif")
```
### Calculating tree cover 
```{r setup_treecover_raster_25, eval=FALSE}
mosaicked_raster_NDVI <- terra::project(mosaicked_raster_NDVI, reclassified_raster_25)

mosaicked_raster_NDVI <- terra::crop(mosaicked_raster_NDVI, reclassified_raster_25, mask=TRUE)

tree_cover <- (mosaicked_raster_NDVI == 1) & (reclassified_raster_25 == 3)
plot(tree_cover)

writeRaster(tree_cover, "treecover_25.tif", overwrite = TRUE)
```
### Plotting tree cover (WGS 84 / Pseudo-Mercator (EPSG:3857))
```{r import_tree_cover25}
tree_cover <- rast("treecover_25.tif")
san_fran_sf <- read_sf("sf/sfoutline.shp")%>%
  st_transform(crs = crs(tree_cover))

# Create a bounding box around the entire raster to reverse the mask
bounding_box <- st_as_sfc(st_bbox(tree_cover))

# Subtract San Francisco outline from the bounding box to create the inverted mask
reverse_mask <- st_difference(bounding_box, st_union(san_fran_sf))

# Mask the raster to keep only San Francisco
tree_cover_cropped <- mask(tree_cover, vect(reverse_mask), inverse = TRUE)
tree_cover_cropped <- crop(tree_cover_cropped, vect(san_fran_sf))

# Reclassify the raster: NA and 0 to gray, 1 to green
reclassified_matrix <- matrix(c(NA, NA, 0, 0, 0, 1, 1, 2), ncol = 2, byrow = TRUE)
tree_cover_reclassified <- classify(tree_cover_cropped, reclassified_matrix, right = NA)

# Convert to factor for proper tmap coloring
tree_cover_factor <- as.factor(tree_cover_reclassified)

# Set tmap mode to plot
tmap_mode("plot")

# Plot the map with tmap
tm= tm_shape(tree_cover_factor) +
  tm_raster(style = "cat", palette = c("lightgray", "darkgreen"), labels = c("No Trees", "Trees"), legend.show = FALSE) +
  tm_layout(legend.outside = TRUE, frame = FALSE, title= "San Francisco Urban Tree Canopy, 2022/2023" 
            )+
  tm_shape(san_fran_sf) +
  tm_borders(lwd = 1, col = "darkgray") +
  tm_shape(san_fran_sf)+
  tm_fill("white")+
  tm_scale_bar() +
  tm_compass(position = c("left", "top"))

tmap_save(tm, "urban_tree_canopy.png")
```
### Finding tree cover percent by area, using EPSG:3311 NAD83 / California Albers
```{r tree_cover_percent_setup, eval = FALSE}
# Define the bounds and resolution
xmin <- -221668.3543
ymin <- -31750.9275
xmax <- -206742.5916
ymax <- -17587.9157
resolution <- 0.25  # in meters

# Create a SpatRaster with the defined bounds and resolution
ncols <- round((xmax - xmin) / resolution)
nrows <- round((ymax - ymin) / resolution)

# Create the empty raster
r <- rast(nrows = nrows, ncols = ncols, ext = ext(xmin, xmax, ymin, ymax), resolution = resolution)

crs(r) <- "EPSG:3311"

# Load the raster data
raster_data <- terra::project(tree_cover, r)

writeRaster(raster_data, "treecover_25_3311.tif", overwrite = TRUE)

# Load the neighborhood shapefile
neighborhoods <- st_read("cb_2020_06_bg_500k.shp")%>%
  filter(., COUNTYFP == "075")%>%
  dplyr::select(., AFFGEOID,GEOID, geometry)

st_crs(neighborhoods) <- "EPSG:4326"

# Reproject neighborhoods to match the CRS of the raster
neighborhoods <- st_transform(neighborhoods, crs(raster_data))

results <- list()

# Loop through each polygon and calculate the tree cover percentage
for (i in 1:nrow(neighborhoods)) {
    # Extract the polygon
    neighborhood <- neighborhoods[i, ]
    
    # Extract tree cover values for the current polygon
    tree_cover_values <- extract(raster_data, neighborhood, fun = mean, na.rm = TRUE)
    
    # Calculate percentage of tree cover (assuming binary raster where TRUE = 1 and FALSE = 0)
    percentage_tree_cover <- tree_cover_values * 100  # Multiply by 100 to get percentage
    
    # Print the name of the neighborhood and the calculated percentage
    neighborhood_name <- neighborhood$GEOID  # Adjust to your actual column name for neighborhood names
    print(paste("Neighborhood:", neighborhood_name, "- Tree Cover Percentage:", round(percentage_tree_cover, 2), "%"))
    
    results[[i]] <- data.frame(neighborhood = neighborhood_name, tree_cover_percentage = percentage_tree_cover)
}

final_results <- do.call(rbind, results)

tree_cover_values <- final_results%>%
  dplyr::select(., "neighborhood", "tree_cover_percentage.m_3712212_se_10_060_20220519_NDVI")%>%
  dplyr::rename(., "GEOID" = "neighborhood")%>%
  dplyr::rename(., "tree_cover_percentage" = "tree_cover_percentage.m_3712212_se_10_060_20220519_NDVI")%>%
  dplyr::filter(!is.na(tree_cover_percentage))

# Add the extracted values to the neighborhoods dataframe
joined_values <- left_join(tree_cover_values, neighborhoods, by="GEOID")

joined_values <-  joined_values%>%
  dplyr::select(., GEOID, AFFGEOID, tree_cover_percentage)

write.csv(joined_values, "tree_cover_2.csv", row.names = FALSE)
```
### Plotting Urban Tree Canopy coverage by Census Block
```{r import_tree_cover_percent}
# Load and prepare the data
tree_cover_percent <- read.csv("tree_cover_2.csv") %>%
  dplyr::select(AFFGEOID, tree_cover_percentage)

neighborhoods <- st_read("cb_2020_06_bg_500k.shp") %>%
  filter(COUNTYFP == "075") %>%
  dplyr::select(AFFGEOID, GEOID, geometry)

# Ensure CRS is consistent
st_crs(neighborhoods) <- "EPSG:4326"

# Define extents for Alameda and Alcatraz
alameda_extent <- st_bbox(c(xmin = -122.337094, ymin = 37.775902, xmax = -122.318329, ymax = 37.799330), crs = st_crs(neighborhoods))
alcatraz_extent <- st_bbox(c(xmin = -122.427263, ymin = 37.824158, xmax = -122.418337, ymax = 37.830463), crs = st_crs(neighborhoods))

# Convert extents to sf polygons
alameda_polygon <- st_as_sfc(alameda_extent)
alcatraz_polygon <- st_as_sfc(alcatraz_extent)

# Combine polygons to create exclusion areas
exclude_areas <- st_union(alameda_polygon, alcatraz_polygon)

# Subtract exclusion areas from neighborhoods
neighborhoods <- st_difference(neighborhoods, exclude_areas)%>%
  left_join(., tree_cover_percent, by = "AFFGEOID") %>%
  filter(!is.na(tree_cover_percentage))

label_data <- data.frame(
  name = c("Presidio of San Francisco", "Treasure \nIsland", "Golden Gate Park", "Twin Peaks", "Lake Merced Park", "Glen Canyon Park", "Union Square", "Financial District"),
  lon = c(-122.4727, -122.3708, -122.4862, -122.4477, -122.4934, -122.4520, -122.4074, -122.4014),
  lat = c(37.7989, 37.8165, 37.7694, 37.7544, 37.7285, 37.7386, 37.7879, 37.7946)
)

# Convert label_data to an sf object
label_sf <- st_as_sf(label_data, coords = c("lon", "lat"), crs = 4326)

tmap_mode("plot")
tm=tm_shape(neighborhoods) +
  tm_polygons("tree_cover_percentage", 
              palette = "Greens", 
              title = "Urban Tree Canopy \nCoverage by Census \nBlock Group, %",
              style = "cont", 
              lwd = 0) +  # Remove borders around polygons
  tm_shape(label_sf) +
  tm_layout(legend.outside = TRUE, frame = FALSE)+
  tm_text("name", size = 0.8, col = "black") +  # Adjust size and color of labels as needed
  tm_layout(frame = TRUE, bg.color = "lightgray")+
  tm_scale_bar() +
  tm_compass(position = c("left", "top"))
tmap_save(tm, "percent_coverage.png")
```

```{r calculate_total_coverage}

```

```{r spatial_autocorrelation_neighbors}
treasure_island_extent <- st_bbox(c(xmin = -122.380388, ymin = 37.805822, xmax = -122.358244, ymax = 37.835112), crs = st_crs(neighborhoods))
treasure_island <- st_as_sfc(treasure_island_extent)
neighborhoods_autocorrelation <- st_difference(neighborhoods, treasure_island)

coordsC <- neighborhoods_autocorrelation%>%
  st_centroid()%>%
  st_geometry()
SFC_nb <- neighborhoods_autocorrelation%>%
  poly2nb(., queen=T)
summary(SFC_nb)
#plot them
plot(SFC_nb, st_geometry(coordsC), col="red")
#add a map underneath
plot(neighborhoods_autocorrelation$geometry, add=T)
SFcensus.lw <- SFC_nb %>%
  nb2mat(., style="C")
#using row standardised here

print(sum(SFcensus.lw))
```
```{r global_morans}
SFcensus.lw <- SFC_nb %>%
  nb2listw(., style="C")
I_SFcensus_Global_UTC <- neighborhoods_autocorrelation %>%
  pull(tree_cover_percentage) %>%
  as.vector()%>%
  moran.test(., SFcensus.lw)

I_SFcensus_Global_UTC
```
```{r monte_carlo}
# run a Monte Carlo simulation 599 times
mc_model <- moran.mc(neighborhoods_autocorrelation$tree_cover_percentage, SFcensus.lw, nsim=599)

# inspect
mc_model
```

```{r local_morans}
I_SFC_Local_UTC <- neighborhoods_autocorrelation %>%
  pull(tree_cover_percentage) %>%
  as.vector()%>%
  localmoran(., SFcensus.lw, alternative = "greater")%>%
  as_tibble()

neighborhoods_autocorrelation <- neighborhoods_autocorrelation %>%
  mutate(UTC_I =as.numeric(I_SFC_Local_UTC$Ii))%>%
  mutate(UTC_Iz =as.numeric(I_SFC_Local_UTC$Z.Ii))%>%
  mutate(UTC_p =as.numeric(I_SFC_Local_UTC$'Pr(z > E(Ii))'))

breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)
library(RColorBrewer)
MoranColours<- rev(brewer.pal(8, "RdGy"))
tm_shape(neighborhoods_autocorrelation) +
    tm_polygons("UTC_I",
        style="fixed",
        breaks=breaks1,
        palette=MoranColours,
        midpoint=NA,
        title="Local Moran's I, Urban Tree Canopy Coverage")+
  tm_layout(title = "San Francisco Census Blocks", 
            legend.outside = TRUE) +
  tm_scale_bar(position = c("right", "bottom")) +
  tm_compass(type = "arrow", position = c("left", "top"))
```

```{r local_morans_significance}
signif <- 0.1
# centers the variable of interest around its mean
neighborhoods_autocorrelation <- neighborhoods_autocorrelation %>%
  mutate(mean_UTC = tree_cover_percentage- mean(tree_cover_percentage))%>%
  mutate(mean_UTC = as.vector(mean_UTC))%>%
  mutate(mean_UTCI= UTC_I - mean(UTC_I))%>%
  mutate(quadrant = case_when(mean_UTC>0 & mean_UTCI >0 ~ 4,
         mean_UTC<0 & mean_UTCI <0 ~ 1,
         mean_UTC<0 & mean_UTCI >0 ~ 2,
         mean_UTC>0 & mean_UTCI <0 ~ 3))%>%
  mutate(quadrant=case_when(UTC_p > signif ~ 0, TRUE ~ quadrant))

brks <- c(0,1,2,3,4,5)
colors <- c("#f2f2f2", "#2c8399", "#8ddef2", "#F4A582", "#D6604D")

# had help from chatgpt in formatting this
tm = tm_shape(neighborhoods_autocorrelation) +
    tm_polygons("quadrant",
        style="fixed",
        breaks=brks,
        labels = c("Insignificant P Value","Low UTCC with \nLow UTCC Neighbours","Low UTCC with \nHigh UTCC Neighbours","High UTCC with \nLow UTCC Neighbours","High UTCC with \nHigh UTCC Neighbours"),
        palette=colors,
        title="Centred UTCC and Moran's I",
        legend.show = FALSE)+
  tm_layout(legend.outside = TRUE, frame = FALSE, title= "Local Moran's I \nwith Mean UTCC" 
            )+
  # Add text below the map
    tm_add_legend(
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels = c(
      "Insignificant P Value",
      "Low UTC with \nLow UTC Neighbours",
      "Low UTC with \nHigh UTC Neighbours",
      "High UTC with \nLow UTC Neighbours",
      "High UTC with \nHigh UTC Neighbours"
    ),
    col = colors,  # Set the color values for the legend items
    shape = 15,    # Use filled squares (or other shapes if you prefer)
    size = 2,    # Adjust size of the symbols (boxes)
  ) +
  tm_scale_bar(position = c("right", "bottom")) +
  tm_compass(type = "arrow", position = c("left", "top"))
tmap_save(tm, "LISA_map.png")
```

```{r adding_independent_variables}
population <- read.csv("census_data/Population/DECENNIALDHC2020.P1-Data.csv", skip = 1)%>%
  clean_names(.)%>%
  select(., "geography", "x_total")%>%
  rename(., "GEOID" = "geography", "total_population" = "x_total")%>%
  mutate(GEOID = substr(GEOID, 10, nchar(GEOID) - 3))%>%
  group_by(GEOID) %>%
  summarize(across(everything(), sum, na.rm = TRUE))


race <- read.csv("census_data/Race/DECENNIALDHC2020.P3-Data.csv", skip = 1)%>%
  clean_names(.)%>%
  select(., "geography", "x_total", "x_total_white_alone", "x_total_black_or_african_american_alone", "x_total_american_indian_and_alaska_native_alone", "x_total_asian_alone", "x_total_native_hawaiian_and_other_pacific_islander_alone", "x_total_two_or_more_races")%>%
  rename(., "GEOID" = "geography", "total" = "x_total", "White" = "x_total_white_alone", "Black" = "x_total_black_or_african_american_alone", "Native" = "x_total_american_indian_and_alaska_native_alone", "Asian" = "x_total_asian_alone", "Pacific_Islander" = "x_total_native_hawaiian_and_other_pacific_islander_alone", "Multiple" = "x_total_two_or_more_races")%>%
  mutate(GEOID = substr(GEOID, 10, nchar(GEOID) - 3))%>%
  group_by(GEOID) %>%
  summarize(across(everything(), sum, na.rm = TRUE))%>%
  mutate(., White = White/total)%>%
  mutate(., Black = Black/total)%>%
  mutate(., Native = Native/total)%>%
  mutate(., AAPI = (Asian + Pacific_Islander)/total)%>%
  mutate(., Multiple = Multiple/total)%>%
  select(., GEOID, White, Black, Native, AAPI, Multiple)%>%
  mutate_all(~replace(., is.na(.), 0))

rental <- read.csv("census_data/RentStatus/DECENNIALDHC2020.H4-Data.csv", skip = 1)%>%
  clean_names(.)%>%
  select(., geography, x_total, x_total_owned_with_a_mortgage_or_a_loan, x_total_owned_free_and_clear, x_total_renter_occupied)%>%
  rename(., "GEOID" = "geography", "total" = "x_total", "mortgage" = "x_total_owned_with_a_mortgage_or_a_loan", "clear" = "x_total_owned_free_and_clear", "rent" = "x_total_renter_occupied")%>%
  mutate(GEOID = substr(GEOID, 10, nchar(GEOID) - 3))%>%
  group_by(GEOID) %>%
  summarize(across(everything(), sum, na.rm = TRUE))%>%
  mutate(., owned = (mortgage+clear)/total)%>%
  mutate(., rented = rent/total)%>%
  select(., GEOID, owned, rented)%>%
  mutate_all(~replace(., is.na(.), 0))


neighborhoods_data <- neighborhoods%>%
  st_transform(., "EPSG:3311")%>%
  left_join(., population, "GEOID")%>%
  mutate(., area = st_area(geometry))%>%
  mutate(., pop_density = total_population/area)%>%
  mutate_all(~replace(., is.na(.), 0))%>%
  select(GEOID, tree_cover_percentage, pop_density, geometry)%>%
  left_join(., race, "GEOID")%>%
  left_join(., rental, "GEOID")
  
```

```{r check_skewness}
data <- neighborhoods_data$tree_cover_percentage

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of Tree Cover Percentage is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$pop_density

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of population density is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$White

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage white is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$Black

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage Black is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$Native

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage native is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$AAPI

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage AAPI is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$Multiple

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage multiple races is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$owned

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage owning their own homes is:", round(skewness_value, 2), "\n")

data <- neighborhoods_data$rented

# Calculate skewness
skewness_value <- skewness(data)
cat("The skewness of percentage renting their homes is:", round(skewness_value, 2), "\n")
```
```{r multivariable_linear_regression}
library(units)
neighborhoods_data_for_log <- neighborhoods_data %>%
  mutate(across(where(~ inherits(., "units")), ~ drop_units(.))) %>%
  mutate(across(where(is.numeric), ~ . + 0.05))%>%
  mutate_all(~replace(., is.na(.), 0))

treasure_island_extent <- st_bbox(c(xmin = -122.380388, ymin = 37.805822, xmax = -122.358244, ymax = 37.835112), crs = "EPSG:4326")%>%
  st_transform(., st_crs(neighborhoods_data_for_log))
treasure_island <- st_as_sfc(treasure_island_extent)
neighborhoods_data_for_log <- st_difference(neighborhoods_data_for_log, treasure_island)
# lm() function builds a regression model and stores model output into the object 'modelMLR'
modelMLR <- lm(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log)
# Include the 'scipen=7' argument in the summary() function remove those annoying scientific notation!
options(scipen = 7)
# summary() calls report the output stored in object 'modelMLR'
summary(modelMLR)

vif(modelMLR)
```
```{r}
# Extract residuals from "modelLMR" object and dump into "spatialdatafile" and call the column "RESIDUALS"
neighborhoods_data_for_log$RESIDUALS <- modelMLR$residuals

# Reporting basic summary measures to have an idea of its distribution before plotting them on map
summary(neighborhoods_data_for_log$RESIDUALS)

tm_shape(neighborhoods_data_for_log) + tm_fill("RESIDUALS", style = "cont", midpoint = 0, palette = "-RdBu") +
tm_shape(neighborhoods_data_for_log) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 0.5, legend.text.size = 0.5)
```
```{r}
# Create spatial weights matrix for areas
Weights <- poly2nb(neighborhoods_data_for_log, row.names = neighborhoods_data_for_log$GEOID)
WeightsMatrix <- nb2mat(Weights, style='B')
Residual_WeightMatrix <- mat2listw(WeightsMatrix , style='W')
# Run the test on the regression model output object "modelMLR" using lm.morantest()
lm.morantest(modelMLR, Residual_WeightMatrix, alternative="two.sided")
```

```{r spatial_lag_regression}
# Fit model using lagsarlm()
# reuse spatial weight matrix created earlier as an object called "Residual_WeighMatrix" 
modelSLY <- lagsarlm(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log, Residual_WeightMatrix)

summary(modelSLY)

# extract the residuals for modelSLY object and dump back to original sf spatialdatafile object
neighborhoods_data_for_log$RESID_SLY <- modelSLY$residuals
# use Moran's I test using moran.mc() function
moran.mc(neighborhoods_data_for_log$RESID_SLY, Residual_WeightMatrix, 1000, zero.policy = T)

tm_shape(neighborhoods_data_for_log) + tm_fill("RESID_SLY", style = "cont", midpoint = 0, palette = "-RdBu") +
tm_shape(neighborhoods_data_for_log) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 0.5, legend.text.size = 0.5)

Weights_2.0 <- as(Residual_WeightMatrix, "CsparseMatrix")
trMC <- trW(Weights_2.0, type="MC")
summary(impacts(modelSLY, tr = trMC, R=100), zstats=TRUE)
```

```{r spatial_error_regression}
modelSER <- errorsarlm(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log, Residual_WeightMatrix)

summary(modelSER)

# extract the residuals for modelSLY object and dump back to original sf spatialdatafile object
neighborhoods_data_for_log$RESID_SER <- modelSER$residuals
# use Moran's I test using moran.mc() function
moran.mc(neighborhoods_data_for_log$RESID_SER, Residual_WeightMatrix, 1000, zero.policy = T)

tm_shape(neighborhoods_data_for_log) + tm_fill("RESID_SER", style = "cont", midpoint = 0, palette = "-RdBu") +
tm_shape(neighborhoods_data_for_log) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 0.5, legend.text.size = 0.5)
```
```{r spatial_durbin_linear}
modelSLX <- lmSLX(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log, Residual_WeightMatrix)
summary(modelSLX)

IMPACTS_SLX <- impacts(modelSLX, tr = trMC, R=100)
IMPACTS_SLX

# extract the residuals for modelSLX object and dump back to original sf spatialdatafile object
neighborhoods_data_for_log$RESID_SLX <- modelSLX$residuals
# use Moran's I test using moran.mc() function
moran.mc(neighborhoods_data_for_log$RESID_SLX, Residual_WeightMatrix, 1000, zero.policy = T)
```

```{r mgwr}
# calculate the centroids from geometries
neighborhoods_data_for_log <- st_centroid(neighborhoods_data_for_log)
# insert coordinates into spatialdatafile note longitude column is X and latitude column is Y
neighborhoods_data_for_log <- cbind(neighborhoods_data_for_log, st_coordinates(neighborhoods_data_for_log))

BwG <- gwr.sel(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log, coords = cbind(neighborhoods_data_for_log$X, neighborhoods_data_for_log$Y), adapt = TRUE)
BwG

```
```{r mgwr_contd}
# start timer to time how long it takes to run a gwr() on computer
start.timer <- proc.time()

# gwr() model. You need hatmatrix and se.fit specified as TRUE for testing statistical significance 
gwr.model <- gwr(log10(tree_cover_percentage) ~ log10(pop_density) + log10(White) + log10(Black) + log10(Native) + log10(AAPI) + log10(Multiple) + log10(owned), data = neighborhoods_data_for_log, coords = cbind(neighborhoods_data_for_log$X, neighborhoods_data_for_log$Y), adapt=BwG, hatmatrix=TRUE, se.fit=TRUE)

# end timer and calculate how it took for model to complete churning
end.timer <- proc.time() - start.timer
# report time taken
end.timer

gwr.model
```
```{r write_gwr_data, eval=FALSE}
gwr.data <- as.data.frame(gwr.model$SDF)

# save the output as a csv so you don't have to run the model again and use in the future!
write.csv(gwr.data, file = "gwr_output.csv", row.names = FALSE)
```
```{r gwr_coefficients}
treasure_island_extent <- st_bbox(c(xmin = -122.380388, ymin = 37.805822, xmax = -122.358244, ymax = 37.835112), crs = "EPSG:4326")
treasure_island <- st_as_sfc(treasure_island_extent)

# create neat spatial data frame by keeping first two columns
census_result <- neighborhoods%>%
  dplyr::select(., GEOID, geometry)

treasure_island <- st_transform(treasure_island, st_crs(census_result))
census_result <- st_difference(census_result, treasure_island)

# insert coefficients into census_result object
census_result$CoefLogPop <- gwr.data[,"log10.pop_density."]
census_result$CoefLogWhite <- gwr.data[,"log10.White."]
census_result$CoefLogBlack <- gwr.data[,"log10.Black."]
census_result$CoefLogNative <- gwr.data[,"log10.Native."]
census_result$CoefLogAAPI <- gwr.data[,"log10.AAPI."]
census_result$CoefLogMultiple <- gwr.data[,"log10.Multiple."]
census_result$CoefLogOwned <- gwr.data[,"log10.owned."]

# insert standard errors into census_result object
census_result$SELogPop <- gwr.data[,"log10.pop_density._se"]
census_result$SELogWhite <- gwr.data[,"log10.White._se"]
census_result$SELogBlack <- gwr.data[,"log10.Black._se"]
census_result$SELogNative <- gwr.data[,"log10.Native._se"]
census_result$SELogAAPI <- gwr.data[,"log10.AAPI._se"]
census_result$SELogMultiple <- gwr.data[,"log10.Multiple._se"]
census_result$SELogOwned <- gwr.data[,"log10.owned._se"]

# insert localR2 estimates into lsoa_result object
census_result$localR2 <- gwr.data[,"localR2"]
```
```{r gwr_r2}
# map localR2 to examine model performance
tm_shape(census_result) + tm_fill("localR2", title = "Adaptive: Local R2", style = "cont", midpoint = 0.5, palette = "Spectral") +
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_compass(position = c("right", "top")) +
    tm_scale_bar(position = c("left", "bottom")) +
    tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)
```

```{r comparison}
# Initialize an empty data frame
model_comparison <- data.frame(
  Model = character(),
  R_squared = numeric(),
  Morans_I = numeric(),
  AIC = numeric(),
  stringsAsFactors = FALSE
)

# Example data to fill in the data frame
model_comparison <- rbind(model_comparison, data.frame(
  Model = "Multivariable Linear Regression", 
  R_squared = summary(modelMLR)$r.squared, 
  Morans_I = lm.morantest(modelMLR, Residual_WeightMatrix, alternative = "two.sided")$estimate[[1]], 
  AIC = AIC(modelMLR)
))

model_comparison <- rbind(model_comparison, data.frame(
  Model = "Spatial Lag Regression", 
  R_squared = NA, 
  Morans_I = moran.test(neighborhoods_data_for_log$RESID_SLY, listw = Residual_WeightMatrix)$estimate[[1]], 
  AIC = AIC(modelSLY)
))

model_comparison <- rbind(model_comparison, data.frame(
  Model = "Spatial Error Regression", 
  R_squared = NA, 
  Morans_I = moran.test(neighborhoods_data_for_log$RESID_SER, listw = Residual_WeightMatrix)$estimate[[1]], 
  AIC = AIC(modelSER)
))

model_comparison <- rbind(model_comparison, data.frame(
  Model = "Spatial Durbin Linear", 
  R_squared = NA, 
  Morans_I = moran.test(neighborhoods_data_for_log$RESID_SLX, listw = Residual_WeightMatrix)$estimate[[1]], 
  AIC = AIC(modelSLX)
))

model_comparison <- rbind(model_comparison, data.frame(
  Model = "MGWR", 
  R_squared = (1 - (gwr.model$results$rss / gwr.model$gTSS)), 
  Morans_I = moran.test(log10(neighborhoods_data_for_log$tree_cover_percentage) - gwr.data$pred, listw = Residual_WeightMatrix)$estimate[[1]], 
  AIC = gwr.model$results$AICh
))

# Convert numeric columns to the appropriate data type (if necessary)
model_comparison$R_squared <- as.numeric(model_comparison$R_squared)
model_comparison$Morans_I <- as.numeric(model_comparison$Morans_I)
model_comparison$AIC <- as.numeric(model_comparison$AIC)

# View the final data frame
print(model_comparison)
```
```{r gwr_white}
tm_shape(census_result) + 
tm_fill("CoefLogWhite", title = "Coefficient: Log(White) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogWhite)
# compute t-score statistic
census_result$tstatWhite <- census_result$CoefLogWhite / census_result$SELogWhite
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatWhite,
    breaks=c(min(census_result$tstatWhite), -2, 2, max(census_result$tstatWhite)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Significant Reduction", "Not Significant", "Significant Increase"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent White \nSignificance GWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_Black}
tm_shape(census_result) + 
tm_fill("CoefLogBlack", title = "Coefficient: Log(Black) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogBlack)
# compute t-score statistic
census_result$tstatBlack <- census_result$CoefLogBlack / census_result$SELogBlack
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatBlack,
    breaks=c(min(census_result$tstatBlack), -2, 2, max(census_result$tstatBlack)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Reduction: Significant", "Not Significant", "Increase: Significant"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent Black \nSignificance MGWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_Native}
tm_shape(census_result) + 
tm_fill("CoefLogNative", title = "Coefficient: Log(Native) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogNative)
# compute t-score statistic
census_result$tstatNative <- census_result$CoefLogNative / census_result$SELogNative
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatNative,
    breaks=c(min(census_result$tstatNative), -2, 2, max(census_result$tstatNative)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Reduction: Significant", "Not Significant", "Increase: Significant"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent Native \nSignificance MGWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_AAPI}
tm_shape(census_result) + 
tm_fill("CoefLogAAPI", title = "Coefficient: Log(Owned) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogAAPI)
# compute t-score statistic
census_result$tstatAAPI <- census_result$CoefLogAAPI / census_result$SELogAAPI
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatAAPI,
    breaks=c(min(census_result$tstatAAPI), -2, 2, max(census_result$tstatAAPI)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Significant Reduction", "Not Significant", "Significant Increase"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent AAPI \nSignificance GWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_Multiple}
tm_shape(census_result) + 
tm_fill("CoefLogMultiple", title = "Coefficient: Log(Multiple) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogMultiple)
# compute t-score statistic
census_result$tstatMultiple <- census_result$CoefLogMultiple / census_result$SELogMultiple
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatMultiple,
    breaks=c(min(census_result$tstatMultiple), -2, 2, max(census_result$tstatMultiple)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Reduction: Significant", "Not Significant", "Increase: Significant"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent Multiple \nSignificance MGWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_Owned}
tm_shape(census_result) + 
tm_fill("CoefLogOwned", title = "Coefficient: Log(Owned) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogOwned)
# compute t-score statistic
census_result$tstatOwned <- census_result$CoefLogOwned / census_result$SELogOwned
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatOwned,
    breaks=c(min(census_result$tstatOwned), -2, 2, max(census_result$tstatOwned)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Reduction: Significant", "Not Significant", "Increase: Significant"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Percent Owned \nSignificance MGWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```
```{r gwr_pop_density}
tm_shape(census_result) + 
tm_fill("CoefLogPop", title = "Coefficient: Log(Pop) [%]", style = "cont", midpoint = 0, palette = "RdBu") +
tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
tm_compass(position = c("right", "top")) +
tm_scale_bar(position = c("left", "bottom")) +
tm_layout(frame = FALSE, legend.title.size = 1, legend.text.size = 1)

summary(census_result$CoefLogPop)
# compute t-score statistic
census_result$tstatPop <- census_result$CoefLogPop / census_result$SELogPop
# create significance column with: "Reduction: Significant", "Not Significant", "Increase: Significant" 
census_result$significant <- cut(census_result$tstatPop,
    breaks=c(min(census_result$tstatPop), -2, 2, max(census_result$tstatPop)),
    labels=c("Reduction: Significant","Not Significant", "Increase: Significant"))


tm_shape(census_result) + tm_fill("significant", title="", style = "cat", labels=c("Reduction: Significant", "Not Significant", "Increase: Significant"), palette = c("#D6604D", "#f2f2f2", "#2c8399"), legend.show = FALSE) +
    tm_add_legend(
    title="Pop Density \nSignificance MGWR",
    type = "symbol",  # Use symbols for legend items (color boxes)
    labels=c("Reduction: \nSignificant", "Not Significant", "Increase: \nSignificant"),
    shape=15,
    size=2,
    col=c("#D6604D", "#f2f2f2", "#2c8399"))+
    tm_shape(census_result) + tm_polygons(alpha = 0, border.alpha = 1, border.col = "black") +
    tm_scale_bar(position = c("right", "bottom")) +
    tm_compass(type = "arrow", position = c("left", "top"))+
    tm_layout(frame = FALSE, legend.title.size = 2, legend.text.size = 1, legend.outside = TRUE)
```